{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0542ee1-12a1-44b8-a9cf-541a71df4aa6",
   "metadata": {},
   "source": [
    "# HW 02\n",
    "- Name: Xinyu Li\n",
    "- Course: Computing for Business Research\n",
    "- UNI: xl3228"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14321f51",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c729f2-59ab-4ab0-bc25-176d30ee5102",
   "metadata": {},
   "source": [
    "# Quesetion 01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcdb89b",
   "metadata": {},
   "source": [
    "### Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb34b9c-f913-4caa-b21c-62e0ee95b6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xinyu\\anaconda3\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------United Nations press releases containing the word “crisis”--------------------------------\n",
      "https://press.un.org/en/2023/sgsm21876.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21952.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21852.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21980.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21947.doc.htm\n",
      "https://press.un.org/en/2023/dsgsm1874.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21765.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21806.doc.htm\n",
      "https://press.un.org/en/2023/dsgsm1848.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21978.doc.htm\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "seed_url = 'https://press.un.org/en'\n",
    "urls = [seed_url]\n",
    "seen = {seed_url}\n",
    "opened_press = set()\n",
    "min_links = 10\n",
    "file_index = 0\n",
    "while len(urls) > 0 and len(opened_press) < min_links:\n",
    "    try:\n",
    "        curr_url = urls.pop(0)\n",
    "        req = urllib.request.Request(curr_url,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = urllib.request.urlopen(req).read()\n",
    "        soup = BeautifulSoup(webpage)\n",
    "        tag = soup.find('a', href = \"/en/press-release\", hreflang = \"en\", text = 'Press Release')\n",
    "        if tag:\n",
    "            text = soup.text\n",
    "            if 'crisis' in text.lower():\n",
    "                opened_press.add(curr_url)\n",
    "                file_index += 1\n",
    "                file_name = \"1_\"+str(file_index)+\".txt\"\n",
    "                file = open(file_name,\"w\", encoding = 'utf-8')\n",
    "                file.write(soup.prettify(formatter=\"html\"))\n",
    "                file.close()\n",
    "                \n",
    "    except:\n",
    "        continue\n",
    "    for a_tag in soup.find_all('a',href = True):\n",
    "        org_child_url = a_tag.get('href')\n",
    "        child_url = urllib.parse.urljoin(seed_url, org_child_url)\n",
    "        if child_url not in seen and seed_url in child_url:\n",
    "            seen.add(child_url)\n",
    "            urls.append(child_url)\n",
    "\n",
    "print(\"--------------------------------United Nations press releases containing the word “crisis”--------------------------------\")\n",
    "for link in opened_press:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215df704",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc2ab3c",
   "metadata": {},
   "source": [
    "### Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ab683c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------European Parliament press releases containing the word “crisis”-----------------------------\n",
      "https://www.europarl.europa.eu/news/en/press-room/20230707IPR02421/parliament-adopts-new-rules-to-boost-energy-savings\n",
      "https://www.europarl.europa.eu/news/en/press-room/20221209IPR64426/eu-long-term-budget-needs-urgent-revision-to-cope-with-current-crises\n",
      "https://www.europarl.europa.eu/news/en/press-room/20220909IPR40138/parliament-adopts-new-rules-on-adequate-minimum-wages-for-all-workers-in-the-eu\n",
      "https://www.europarl.europa.eu/news/en/press-room/20210422IPR02615/civil-protection-faster-eu-response-to-large-scale-emergencies\n",
      "https://www.europarl.europa.eu/news/en/press-room/20230929IPR06132/nagorno-karabakh-meps-demand-review-of-eu-relations-with-azerbaijan\n",
      "https://www.europarl.europa.eu/news/en/press-room/20221209IPR64427/holodomor-parliament-recognises-soviet-starvation-of-ukrainians-as-genocide\n",
      "https://www.europarl.europa.eu/news/en/press-room/20210304IPR99207/parliament-gives-green-light-for-new-eu4health-programme\n",
      "https://www.europarl.europa.eu/news/en/press-room/20230210IPR74806/green-deal-industrial-plan-securing-the-eu-s-clean-tech-leadership\n",
      "https://www.europarl.europa.eu/news/en/press-room/20230310IPR77232/minimum-income-schemes-increasing-support-accessibility-and-inclusion\n",
      "https://www.europarl.europa.eu/news/en/press-room/20220321IPR25913/more-eu-action-needed-for-secure-food-supply\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "seed_url = 'https://www.europarl.europa.eu/news/en/press-room'\n",
    "urls = [seed_url]\n",
    "seen = {seed_url}\n",
    "opened_press = set()\n",
    "min_links = 10\n",
    "file_index = 0\n",
    "while len(urls) > 0 and len(opened_press) < min_links:\n",
    "    try:\n",
    "        curr_url = urls.pop(0)\n",
    "        req = urllib.request.Request(curr_url,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = urllib.request.urlopen(req).read()\n",
    "        soup = BeautifulSoup(webpage)\n",
    "        tag1 = soup.find('span', class_ = \"ep_name\", text = 'Plenary session')\n",
    "        tag2 = soup.find('span', class_ = \"ep_name\", text = 'Press Releases')\n",
    "        if tag1 and tag2:\n",
    "            text = soup.text\n",
    "            if 'crisis' in text.lower():\n",
    "                opened_press.add(curr_url)\n",
    "                file_index += 1\n",
    "                file_name = \"2_\"+str(file_index)+\".txt\"\n",
    "                file = open(file_name,\"w\",encoding = 'utf-8')\n",
    "                file.write(soup.prettify(formatter=\"html\"))\n",
    "                file.close()\n",
    "    except:\n",
    "        continue\n",
    "    for a_tag in soup.find_all('a',href = True):\n",
    "        org_child_url = a_tag.get('href')\n",
    "        child_url = urllib.parse.urljoin(seed_url, org_child_url)\n",
    "        if child_url not in seen and seed_url in child_url:\n",
    "            seen.add(child_url)\n",
    "            urls.append(child_url)\n",
    "\n",
    "print(\"-----------------------------European Parliament press releases containing the word “crisis”-----------------------------\")\n",
    "for link in opened_press:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f868df",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627702df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
